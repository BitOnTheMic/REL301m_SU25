Khái niệm	Giải thích đơn giản
Reward (Phần thưởng)	Là giá trị nhận được ngay sau khi chọn một tay gạt (arm). Mỗi tay gạt có phân phối phần thưởng riêng, có thể ngẫu nhiên.
Tính chất thời gian	Bài toán xảy ra theo từng bước, lặp lại nhiều lần. Mỗi lần chọn tay gạt và nhận phần thưởng, mục tiêu là tích lũy nhiều phần thưởng nhất theo thời gian.
K-Armed Bandit	Là bài toán chọn giữa k lựa chọn (tay gạt) mà ta không biết rõ phần thưởng của chúng, để tối đa hóa tổng phần thưởng nhận được.
Action-Value (Giá trị hành động)	Là giá trị kỳ vọng (trung bình) của phần thưởng cho mỗi tay gạt. Giá trị này được ước lượng dần qua nhiều lần chọn, giúp quyết định nên chọn tay nào.
 Chiến lược ước lượng Action-Value
Phương pháp	Giải thích
Trung bình mẫu (Sample-Average)	Tính trung bình tất cả phần thưởng đã nhận được cho một tay gạt.
Epsilon-Greedy	Đôi khi chọn tay gạt ngẫu nhiên để khám phá (với xác suất ε), còn lại chọn tay tốt nhất hiện tại.
Thompson Sampling	Lấy mẫu phần thưởng giả định từ mỗi tay theo phân phối, chọn tay có giá trị mẫu cao nhất.
