{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maamml2Z8kAv"
      },
      "source": [
        "# What is an MDP? (Markov Decision Process)\n",
        "An MDP is a mathematical framework used to describe sequential decision-making problems where outcomes are partly random and partly under the control of a decision-maker (called the agent).\n",
        "### Components of an MDP:\n",
        "Component\tDescription\n",
        "\n",
        "**(States)**The set of possible situations the agent can be in.\n",
        "\n",
        "**(Actions)**\tThe set of actions the agent can choose from in each state.\n",
        "\n",
        "**(Transition Probability)**\tThe probability of moving to a next state and receiving a reward, given the current state and action.\n",
        "\n",
        "**(Reward)**\tThe immediate reward received after taking an action in a state.\n",
        "\n",
        "**(Gamma)**\tThe discount factor: how much the agent values future rewards.\n",
        "### Define K-armed\n",
        "1. **K**    : The number of different actions (or arms) available to the agent.\n",
        "2. **Arms** : Each arm represents a different action that the agent can take. Each arm has an associated reward distribution.\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
